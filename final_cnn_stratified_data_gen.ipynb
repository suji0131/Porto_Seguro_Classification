{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sorts strings properly\n",
    "def natural_sort(l):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ]\n",
    "    return sorted(l, key = alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "data class has the dataframe, keeps track of its bin, cat, ord etc. col names and has summary of cont. and ord. cols\n",
    "'''\n",
    "class data:\n",
    "    '''\n",
    "    filename: path of csv file to be read\n",
    "    '''\n",
    "    def __init__(self, filename):\n",
    "        self.df = pd.read_csv(filename)\n",
    "        \n",
    "        #don't use cols_ anywhere except in init\n",
    "        self.cols_ = self.df.columns.tolist()\n",
    "        \n",
    "        self.float_cols = self.df.select_dtypes(include=['float64']).columns.tolist()\n",
    "        #cat and bin column names\n",
    "        self.cat_col_names = [col for col in self.cols_ if '_cat' in col]\n",
    "        self.bin_col_names = [col for col in self.cols_ if '_bin' in col]\n",
    "\n",
    "        self.ord_col_names = []\n",
    "        for col in self.cols_:\n",
    "            if ('_cat' in col) or ('_bin' in col) or (col in ['id', 'target']) or (col in self.float_cols):\n",
    "                a = 1\n",
    "            else:\n",
    "                self.ord_col_names.append(col)\n",
    "                \n",
    "        # integer columns and float columns summary (mean, median, min, max) \n",
    "        self.column_summary = {}\n",
    "        for col in self.float_cols+self.ord_col_names:\n",
    "            t_d = {}\n",
    "            t_d['median'] = self.df[col].dropna().median()\n",
    "            t_d['mean'] = self.df[col].dropna().mean()\n",
    "            t_d['max'] = self.df[col].dropna().max()\n",
    "            t_d['min'] = self.df[col].dropna().min()\n",
    "            t_d['range'] = t_d['max'] - t_d['min']\n",
    "            self.column_summary[col] = t_d\n",
    "    \n",
    "    '''\n",
    "    removes the column from dataframe and its name from appropriate list\n",
    "    col_name_list_: is a list of columns to be removed\n",
    "    '''            \n",
    "    def remove_cols(self, col_name_list_):\n",
    "        for col_name in col_name_list_:  \n",
    "            self.df.drop([col_name],axis=1, inplace = True)\n",
    "            if col_name in self.cat_col_names:\n",
    "                self.cat_col_names.remove(col_name)\n",
    "            elif col_name in self.float_cols:\n",
    "                self.float_cols.remove(col_name)\n",
    "            elif col_name in self.bin_col_names:\n",
    "                self.bin_col_names.remove(col_name)\n",
    "            elif col_name in self.ord_col_names:\n",
    "                self.ord_col_names.remove(col_name)\n",
    "                \n",
    "    def sort_df(self):\n",
    "        ordered_cols = natural_sort(self.df.columns.tolist())\n",
    "        self.df = self.df[ordered_cols]\n",
    "        \n",
    "    def get_dummies(self):\n",
    "        self.df = pd.get_dummies(self.df,columns=self.cat_col_names,prefix=self.cat_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pipeline fn should be executed after creating train as it is used in that function\n",
    "train = data('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "temp_data: it should be a data object\n",
    "'''\n",
    "def pipeline(temp_data, dummy_var=False):\n",
    "    drop_cols = ['ps_car_03_cat','ps_car_05_cat', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin','ps_ind_13_bin', \n",
    "                'ps_car_10_cat', 'ps_ind_14']\n",
    "    temp_data.remove_cols(drop_cols)\n",
    "    \n",
    "    '''\n",
    "    I'm treating ord cols as cont. variables for this problem.\n",
    "    replace null values with median and makes the column mean 0 and every value bt -1 and +1\n",
    "    '''\n",
    "    for col in temp_data.float_cols + temp_data.ord_col_names:\n",
    "        #replacing nan values with median for float and integer columns\n",
    "        #here for this problem -1 means nan\n",
    "        #for categorical variables we will make all the dummy variables zero\n",
    "        \n",
    "        temp_data.df[col].replace(-1, train.column_summary[col]['median'],inplace=True)\n",
    "        temp_data.df[col] = (temp_data.df[col] - train.column_summary[col]['min'])/(train.column_summary[col]['range']+0.0001)\n",
    "    if dummy_var:\n",
    "        temp_data.get_dummies()\n",
    "    temp_data.sort_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline(train, dummy_var=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train.df.drop(['id','target'], axis=1).as_matrix()\n",
    "y = train.df['target'].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified Shuffle split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#startified shuffle split will split data into train, test and validation with same ratio as\n",
    "#target classes\n",
    "sss = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=0)\n",
    "a = sss.split(X, y)\n",
    "for train_index, test_index in a:\n",
    "    x_train, x_val = X[train_index], X[test_index]\n",
    "    y_train, y_val = y[train_index], y[test_index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (476169, 213) (476169,)\n",
      "Validation shape:  (119043, 213) (119043,)\n"
     ]
    }
   ],
   "source": [
    "print('Training shape: ', np.shape(x_train), np.shape(y_train))\n",
    "print('Validation shape: ', np.shape(x_val), np.shape(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [(x_train,y_train),(x_val,y_val)]\n",
    "with open('data_us.pickle', 'wb') as handle:\n",
    "    pickle.dump(data, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
